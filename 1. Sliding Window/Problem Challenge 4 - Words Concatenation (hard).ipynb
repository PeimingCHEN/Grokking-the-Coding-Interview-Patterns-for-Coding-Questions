{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Challenge 4: Words Concatenation (hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "Given a string and a list of words, find all the starting indices of substrings in the given string that are a **concatenation of all the given words** exactly once **without any overlapping** of words. It is given that all words are of the **same length**.<br>\n",
    "Leetcode: [30. Substring with Concatenation of All Words](https://leetcode.com/problems/substring-with-concatenation-of-all-words/)\n",
    "\n",
    "##### Example 1\n",
    "**Input**: String=\"catfoxcat\", Words=[\"cat\", \"fox\"]<br>\n",
    "**Output**: [0, 3]<br>\n",
    "**Explanation**: The two substring containing both the words are \"catfox\" & \"foxcat\".<br>\n",
    "\n",
    "##### Example 2\n",
    "**Input**: String=\"catcatfoxfox\", Words=[\"cat\", \"fox\"]<br>\n",
    "**Output**: [3]<br>\n",
    "**Explanation**: The only substring containing both the words is \"catfox\".<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "Has a lot of similarities with **Maximum Sum Subarray of Size K**. Track all the words in a **HashMap**.<br>\n",
    "1. Keep the frequency of every word in a HashMap.\n",
    "2. Starting from every index in the string, try to match all the words.\n",
    "3. In each iteration, keep track of all the words that we have already seen in another HashMap.\n",
    "4. If a word is not found or has a higher frequency than required, we can move on to the next character in the string.\n",
    "5. Store the index if we have found all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3]\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "def find_word_concatenation(str1, words):\n",
    "    if len(words)==0:\n",
    "        return []\n",
    "    word_frequency = {}\n",
    "    result_indices = []\n",
    "    word_length = len(words[0])\n",
    "    word_count = len(words)\n",
    "    # create a hashmap to store word frequency\n",
    "    for word in words:\n",
    "        if word not in word_frequency:\n",
    "            word_frequency[word] = 0\n",
    "        word_frequency[word] += 1\n",
    "    \n",
    "    for i in range(len(str1) - word_count * word_length + 1):\n",
    "        word_seen = {} # track the words that have alread seen\n",
    "        for j in range(word_count):\n",
    "            next_word_index = i + j * word_length\n",
    "            # Get the next word from the string\n",
    "            word = str1[next_word_index: next_word_index + word_length]\n",
    "            \n",
    "            # Break if we don't need this word\n",
    "            if word not in word_frequency:\n",
    "                break\n",
    "\n",
    "            # Add the word to the 'words_seen' map\n",
    "            if word not in word_seen:\n",
    "                word_seen[word] = 0\n",
    "            word_seen[word] += 1\n",
    "            \n",
    "            # No need to process further if the word has higher frequency than required\n",
    "            if word_seen[word] > word_frequency[word]:\n",
    "                break\n",
    "            \n",
    "             # Store index if we have found all the words\n",
    "            if j + 1 == word_count:\n",
    "                result_indices.append(i)\n",
    "    return result_indices\n",
    "\n",
    "def main():\n",
    "  print(find_word_concatenation(\"catfoxcat\", [\"cat\", \"fox\"]))\n",
    "  print(find_word_concatenation(\"catcatfoxfox\", [\"cat\", \"fox\"]))\n",
    "\n",
    "main()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time Complexity**: $O(N * M * Len)$, where 'N' is the number of characters in the given string, 'M' is the total number of words, and 'Len' is the length of a word.<br> \n",
    "$O(Len)$ is for slicing a list. Slicing is just \"copy part of the list\" so time complexity is the same as copy.<br>\n",
    "**Space Complexity**: $O(M + N)$, at most, we need $O(M)$ to store all the words in the two HashMaps. We also need $O(N)$ for the result list."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8b40d688a12481f01eadf7380c47edd8a49484a47dba3db091451640e880c68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
